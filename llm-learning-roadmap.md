# LLM学習ロードマップ v1.0

## 📋 はじめに

このロードマップは、LLMアプリケーション開発スキルを**実践を通じて着実に習得**することを目的としています。

### 🎯 このロードマップのゴール

**12ヶ月後のあなた：**
1. LLMを組み込んだアプリケーションを自力で開発・デプロイできる
2. RAGシステムを実装し、精度改善を実践できる  
3. ファインチューニングを含む高度な最適化ができる

### 📊 学習方針

**「必要最低限を学んで、すぐに手を動かす」**

- ✅ 理論は最小限、実践中心
- ✅ 動くものを最優先
- ✅ 完璧主義より継続を重視

---

## ✅ 事前スキルチェック

### 必須スキル
- [ ] 基本的なプログラミング概念（変数、関数、ループ）を理解している
- [ ] コマンドライン操作の基礎ができる
- [ ] テキストエディタ（VSCode等）を使える

### あると良いスキル
- [ ] Pythonの基礎知識がある
- [ ] Git/GitHubの使用経験がある
- [ ] Web APIの基本概念を理解している

**📝 スキルが不足している場合**：各項目について1-2週間の事前学習を推奨

---

## 🗓️ 全体スケジュール

| Phase | 期間 | 目標 | 週あたり学習時間 |
|-------|------|------|-----------------|
| **Phase 1** | 0-3ヶ月 | シンプルなLLMアプリを開発 | 10-12時間 |
| **Phase 2** | 3-6ヶ月 | 実用的なRAGシステムを構築 | 10-12時間 |
| **Phase 3** | 6-12ヶ月 | ファインチューニングとカスタマイズ | 12-14時間 |

---

## 💰 予算計画ガイド

### API利用料金の目安（月額）

| Phase | 予算目安 | 主な用途 |
|-------|---------|----------|
| **Phase 1** | $5-20 | GPT-3.5-turbo/Claude Haiku での実験 |
| **Phase 2** | $20-50 | Embeddings API、RAG実装 |
| **Phase 3** | $50-200+ | GPU利用、大規模データ処理 |

### コスト削減のコツ
1. **開発時は安価なモデルを使用**（GPT-4o-mini、Claude Haiku）
2. **レスポンスをキャッシュ**して同じクエリを繰り返さない
3. **無料クレジット**を活用（OpenAI $5、Anthropic $5）
4. **ローカルLLM**（Ollama）で初期実験

---

## 🔧 2025年版 推奨技術スタック

### LLMモデル選択ガイド

| 用途 | 推奨モデル | コスト目安 | 特徴 |
|------|------------|-----------|------|
| **学習・実験** | Claude 3.5 Haiku, GPT-4o-mini | $0.25/1M tokens | 高速・安価 |
| **本番・高精度** | Claude 3.5 Sonnet, GPT-4o | $3-15/1M tokens | 高精度・高機能 |
| **ローカル実行** | Llama 3.2, Gemma 2, Qwen 2.5 | 無料（GPU必要） | プライバシー重視 |

### 開発環境・ツール

| カテゴリ | 推奨ツール | 代替 |
|---------|-----------|------|
| **エディタ** | Cursor (AI支援) | VSCode + Copilot |
| **パッケージ管理** | uv | pip, poetry |
| **API テスト** | Bruno | Postman, Insomnia |
| **バージョン管理** | Git + GitHub | GitLab |

---

## 🚀 Phase 1: 基礎固め + アプリ開発入門 (0-3ヶ月)

### 🎯 Phase目標
最小限の知識でLLMアプリを作り、動かす経験を積む

### 📊 卒業条件
- [ ] LLM APIを使った基本的なアプリを自力で実装できる
- [ ] プロンプトエンジニアリングの基本技術を使える
- [ ] FastAPIでWeb APIを作成できる
- [ ] Dockerでアプリをコンテナ化できる

### 🔑 重要スキル習得順序

#### 第1-4週: 基礎構築
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| Python基礎（既習なら省略） | ⭐⭐⭐⭐⭐ | 20時間 |
| LLM API の基本 | ⭐⭐⭐⭐⭐ | 15時間 |
| プロンプトエンジニアリング | ⭐⭐⭐⭐⭐ | 10時間 |

#### 第5-8週: アプリケーション開発
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| LangChain基礎 | ⭐⭐⭐⭐ | 15時間 |
| 構造化出力（Pydantic） | ⭐⭐⭐⭐ | 10時間 |
| エラーハンドリング | ⭐⭐⭐⭐ | 8時間 |

#### 第9-12週: Web化とデプロイ
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| FastAPI基礎 | ⭐⭐⭐⭐ | 15時間 |
| Docker基礎 | ⭐⭐⭐ | 15時間 |
| デプロイ（Render/Railway） | ⭐⭐ | 10時間 |

### 📝 マイルストーン成果物

1. **Week 2**: CLIチャットボット（`simple_chat.py`）
2. **Week 4**: プロンプト最適化済みボット（`cli_chatbot.py`）
3. **Week 6**: LangChain文書要約ツール（`summarizer.py`）
4. **Week 8**: 構造化データ抽出ツール（`data_extractor.py`）
5. **Week 10**: FastAPI Webアプリ（`app/main.py`）
6. **Week 12**: Dockerized LLMアプリ（完成版）

---

## 🔥 Phase 2: RAGと精度向上の実践 (3-6ヶ月)

### 🎯 Phase目標
実用的なRAGシステムを構築し、精度改善の施策を実装できるようになる

### 📊 卒業条件
- [ ] ベクトルDBを使ったRAGシステムを実装できる
- [ ] 評価指標を設定し、改善効果を測定できる
- [ ] チャンキング戦略を比較実験できる
- [ ] エージェントシステムの基本を実装できる

### 🔑 重要スキル習得順序

#### 第4ヶ月: RAG基礎
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| Embeddings概念と実装 | ⭐⭐⭐⭐⭐ | 15時間 |
| ベクトルDB（ChromaDB） | ⭐⭐⭐⭐⭐ | 15時間 |
| RAGアーキテクチャ | ⭐⭐⭐⭐⭐ | 20時間 |

#### 第5ヶ月: 評価と最適化
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| 評価手法（RAGAS） | ⭐⭐⭐⭐⭐ | 15時間 |
| チャンキング最適化 | ⭐⭐⭐⭐ | 15時間 |
| リランキング | ⭐⭐⭐ | 10時間 |

#### 第6ヶ月: エージェントと運用
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| LangGraph基礎 | ⭐⭐⭐ | 20時間 |
| Tool Calling | ⭐⭐⭐ | 15時間 |
| モニタリング（LangSmith） | ⭐⭐⭐ | 10時間 |

### 📝 マイルストーン成果物

1. **Month 4**: 基本的なRAGシステム
2. **Month 5**: 評価・改善レポート（数値付き）
3. **Month 6**: RAG + エージェント統合システム

---

## 🎓 Phase 3: ファインチューニングと高度な最適化 (6-12ヶ月)

### 🎯 Phase目標
ファインチューニングを実施し、モデルをカスタマイズできるようになる

### 📊 卒業条件
- [ ] PyTorchの基本操作ができる
- [ ] Hugging Face Transformersでモデルを扱える
- [ ] LoRA/QLoRAでファインチューニングできる
- [ ] 最適化されたモデルをデプロイできる

### 🔑 重要スキル習得順序

#### 第7-8ヶ月: 深層学習基礎
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| 機械学習基礎理論 | ⭐⭐⭐⭐⭐ | 20時間 |
| PyTorch基礎 | ⭐⭐⭐⭐⭐ | 30時間 |
| Hugging Face Transformers | ⭐⭐⭐⭐⭐ | 25時間 |

#### 第9-10ヶ月: ファインチューニング実践
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| PEFT（LoRA/QLoRA） | ⭐⭐⭐⭐⭐ | 30時間 |
| データセット構築 | ⭐⭐⭐⭐⭐ | 25時間 |
| 評価とベンチマーク | ⭐⭐⭐⭐ | 20時間 |

#### 第11-12ヶ月: 本番運用
| スキル | 必須度 | 学習時間 |
|--------|--------|----------|
| モデルサービング（vLLM） | ⭐⭐⭐⭐ | 20時間 |
| 量子化と最適化 | ⭐⭐⭐ | 20時間 |
| 統合システム構築 | ⭐⭐⭐⭐ | 30時間 |

### 📝 マイルストーン成果物

1. **Month 8**: 公開データセットでのファインチューニング
2. **Month 10**: 独自データでのLoRAファインチューニング
3. **Month 12**: 本番対応の統合LLMシステム

---

## 🔥 よくあるエラーと解決法

### API関連エラー

| エラー | 原因 | 解決法 |
|--------|------|--------|
| **RateLimitError** | リクエスト制限超過 | exponential backoffでリトライ実装、`time.sleep()` 追加 |
| **InvalidAPIKey** | APIキー設定ミス | `.env`ファイルの位置確認、環境変数名を確認 |
| **ContextLengthExceeded** | トークン数超過 | チャンク分割、要約処理を追加、小さいコンテキストウィンドウ |

### 環境構築エラー

| エラー | 原因 | 解決法 |
|--------|------|--------|
| **ModuleNotFoundError** | パッケージ未インストール | `pip install -r requirements.txt` 実行 |
| **CUDA out of memory** | GPU メモリ不足 | バッチサイズ削減、gradient accumulation使用 |
| **Docker build失敗** | 依存関係の問題 | ベースイメージ更新、キャッシュクリア |

---

## 📚 必須リソース集

### Phase 1 学習リソース

#### 基礎学習
- 📘 [Python公式チュートリアル](https://docs.python.org/ja/3/tutorial/) - 日本語
- 📘 [OpenAI Quickstart](https://platform.openai.com/docs/quickstart) - 英語
- 📘 [Anthropic Documentation](https://docs.anthropic.com/) - 英語
- 📘 [Prompt Engineering Guide](https://www.promptingguide.ai/jp) - 日本語

#### フレームワーク
- 📘 [LangChain公式](https://python.langchain.com/) - 英語
- 📘 [FastAPI Tutorial](https://fastapi.tiangolo.com/ja/) - 日本語
- 📘 [Docker入門](https://docs.docker.jp/get-started/) - 日本語

### Phase 2 学習リソース

#### RAG関連
- 📘 [LlamaIndex Docs](https://docs.llamaindex.ai/) - 英語
- 📘 [ChromaDB Docs](https://docs.trychroma.com/) - 英語
- 📘 [RAGAS Documentation](https://docs.ragas.io/) - 英語

### Phase 3 学習リソース

#### 深層学習・ファインチューニング
- 📘 [PyTorch Tutorials](https://pytorch.org/tutorials/) - 英語
- 📘 [Hugging Face Course](https://huggingface.co/learn/nlp-course/) - 英語
- 📘 [PEFT Documentation](https://huggingface.co/docs/peft/) - 英語

### 継続学習のための情報源

#### 最新情報
- 🔬 [arXiv cs.CL](https://arxiv.org/list/cs.CL/recent) - 最新論文
- 📝 [Hugging Face Papers](https://huggingface.co/papers) - 日次論文要約
- 📺 [Andrej Karpathy YouTube](https://www.youtube.com/@AndrejKarpathy) - 教育動画

#### コミュニティ
- 💬 [Hugging Face Discord](https://discord.gg/hugging-face)
- 💬 [LangChain Discord](https://discord.gg/langchain)
- 💬 Reddit: r/LocalLLaMA

---

## 💡 成功のための5つの原則

### 1. 📈 小さく始めて大きく育てる
- 最初のコードは10行でもOK
- 動くことを最優先
- 徐々に機能追加

### 2. 🔄 毎日の継続
- 1日15分でも手を動かす
- GitHubに毎日コミット
- 習慣化が最重要

### 3. 📝 アウトプット重視
- 学んだらすぐ実装
- ブログやSNSで共有
- 成果物を作る

### 4. 🤝 コミュニティ活用
- 詰まったら質問
- Discord/Slackに参加
- 他の人の質問から学ぶ

### 5. 🎯 実用的なプロジェクト
- 自分が使いたいものを作る
- 仕事に活かせるテーマを選ぶ
- 興味のある分野で実装

---

## 📊 進捗管理テンプレート

### Phase 1 チェックリスト（3ヶ月）
```markdown
## Month 1
- [ ] Week 1-2: Python + API基礎
- [ ] Week 3-4: プロンプトエンジニアリング
  
## Month 2  
- [ ] Week 5-6: LangChain入門
- [ ] Week 7-8: 構造化出力

## Month 3
- [ ] Week 9-10: Web API化
- [ ] Week 11-12: Docker化

完了日: _____
```

### Phase 2 チェックリスト（3ヶ月）
```markdown
## Month 4
- [ ] Week 1-2: Embeddings基礎
- [ ] Week 3-4: RAG実装

## Month 5
- [ ] Week 1-2: 評価基盤構築
- [ ] Week 3-4: 改善施策実施

## Month 6  
- [ ] Week 1-2: エージェント開発
- [ ] Week 3-4: モニタリング

完了日: _____
```

### Phase 3 チェックリスト（6ヶ月）
```markdown
## Month 7-8
- [ ] PyTorch基礎
- [ ] Transformers習得
- [ ] 初回ファインチューニング

## Month 9-10
- [ ] LoRA実装
- [ ] 独自データセット構築
- [ ] カスタムファインチューニング

## Month 11-12
- [ ] モデルサービング
- [ ] 最適化実施
- [ ] 統合システム完成

完了日: _____
```

### 学習ログテンプレート
```markdown
## 日付: YYYY/MM/DD
### 今日学んだこと
- 
### 実装したこと
- 
### つまずいた点と解決法
- 
### 明日の目標
- 
```

---

## 🚦 つまずいた時のチェックリスト

### 学習が停滞している時
- [ ] タスクを細分化しているか？
- [ ] 完璧主義になっていないか？
- [ ] 1日15分でも手を動かしているか？
- [ ] 適切に休息を取っているか？

### 技術的に詰まった時
- [ ] エラーメッセージを正確に読んだか？
- [ ] 公式ドキュメントを確認したか？
- [ ] 同じエラーで検索したか？
- [ ] コミュニティに質問したか？

### モチベーションが下がった時
- [ ] 小さな成功体験を作れているか？
- [ ] 成果物を他人に見せたか？
- [ ] 実用的なテーマを選んでいるか？
- [ ] 適度な休息を取っているか？

---

## 🎯 最終チェックポイント

### Phase 1 完了時
✅ LLM APIを使ったWebアプリが作れる  
✅ プロンプトエンジニアリングができる  
✅ Dockerでアプリをコンテナ化できる

### Phase 2 完了時
✅ RAGシステムを構築できる  
✅ 評価指標で改善効果を測定できる  
✅ エージェントの基本実装ができる

### Phase 3 完了時
✅ ファインチューニングができる  
✅ LoRA/QLoRAを適用できる  
✅ 本番環境にデプロイできる

---

## 🚀 さあ、始めましょう！

このロードマップは**ガイドライン**です。あなたのペースで進めてください。

**重要なのは完璧さではなく継続です。**

最初の一歩を踏み出すことが、最も大切なステップです。

**1年後のあなたは、LLMマスターです！** 🎉

---

### 📝 改訂履歴
- v2.0 (2025年1月): 構造最適化、コスト情報追加、エラー対処法強化
- v1.0 (2024年12月): 初版リリース

### 📮 フィードバック
このロードマップへのご意見・ご感想をお待ちしています。  
改善提案やつまずいたポイントがあれば、ぜひ共有してください。

---

_Copyright © 2025 - LLM Learning Roadmap v2.0_
